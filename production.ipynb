{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import glob\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions for logger, garbage collecting, creating dataframe, saving dataframe\n",
    "path = r'D:\\DE-Project 1 data\\Bronze'\n",
    "save_folder = r'D:\\\\DE-Project 1 data\\Silver'\n",
    "logfile = save_folder + r'/log.txt'\n",
    "\n",
    "'''\n",
    "Writes a timestamped message to a log file\n",
    "\n",
    "Parameters:\n",
    "----------\n",
    "log_file: str\n",
    "    file path of log file\n",
    "message : str\n",
    "    log message to be appended to log file\n",
    "'''\n",
    "def log_change(log_file, message):\n",
    "    with open(log_file, 'a') as f:\n",
    "        message =  pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S') +'--- ' + message + '\\n'\n",
    "        f.write(message)\n",
    "\n",
    "\n",
    "'''\n",
    "Marks an object for the garbage collector to delete, then deletes the object from memory\n",
    "\n",
    "Parameter:\n",
    "----------\n",
    "obj: object\n",
    "    object to be deleted\n",
    "'''\n",
    "def delete(obj):\n",
    "    a = [obj]\n",
    "    del a\n",
    "    del obj\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "'''\n",
    "Loading multiple csv files from a specified folder path into one Dataframe\n",
    "\n",
    "Parameters:\n",
    "folder_name: str\n",
    "    folder path\n",
    "usecols_list: list of str\n",
    "    columns that you want to extract from the data\n",
    "\n",
    "Returns:\n",
    "df: pd.DataFrame\n",
    "    combined dataframe\n",
    "csv_files: list of str\n",
    "    list of all of the csv files combined\n",
    "'''\n",
    "def multiple_csv_df(folder_name, usecols_list):\n",
    "    print('Reading csv files...')\n",
    "    csv_files = glob.glob(path + '/*/' + folder_name + '/*.csv')\n",
    "    df_list = (pd.read_csv(file, usecols=usecols_list, low_memory=False) for file in csv_files)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Free df list memory\n",
    "    del df_list\n",
    "    gc.collect()\n",
    "    \n",
    "    return df, csv_files\n",
    "\n",
    "\n",
    "'''\n",
    "Saving Dataframe as a csv into specified cleaned folder\n",
    "\n",
    "Parameters:\n",
    "df: pd.Dataframe\n",
    "    Dataframe to save as csv\n",
    "csv_files: list of str\n",
    "    list of the file names of globbed together csv's \n",
    "save_folder: str\n",
    "    save folder path\n",
    "'''\n",
    "def save_csv(df, csv_files, save_folder):\n",
    "    print('Saving csv file...')\n",
    "    file_name = re.sub(r'_(\\d+)_|part_0', '', re.split(r'\\\\',csv_files[0])[-1])\n",
    "    save_path = save_folder + '/' + file_name\n",
    "    df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions to clean the data\n",
    "##-------- container.csv\n",
    "'''\n",
    "To chop off inches in 'FFFII' formatted measurements in container.csv\n",
    "\n",
    "Parameter:\n",
    "x: int\n",
    "    measurement in integer form\n",
    "\n",
    "Returns:\n",
    "int\n",
    "    reformatted number with removed inches \n",
    "'''\n",
    "def chop_inches(x):\n",
    "    if x >= 100:\n",
    "        return int(str(x)[:-2])\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "##-------- header.csv\n",
    "class codeDict(dict):\n",
    "    def __missing__(self, key):\n",
    "        return key\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Translates a pd.Dataframe column using a dictionary \n",
    "\n",
    "Parameters:\n",
    "df : pd.Dataframe\n",
    "    dataframe to be manipulated\n",
    "code_type: str\n",
    "    name of column to be translated that will be dropped\n",
    "variable: str\n",
    "    name of new translated column\n",
    "\"\"\"\n",
    "def translate(df, code_type, variable):\n",
    "    translation_dict = code_dict(code_type, variable)\n",
    "    df[variable] = df[code_type].map(translation_dict)\n",
    "\n",
    "    df.drop(columns=[code_type], inplace=True)\n",
    "\n",
    "    delete(translation_dict)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Turns a csv file with two columns into a dictionary \n",
    "with the first column being the key and the second is the value\n",
    "\n",
    "Parameters:\n",
    "code_type: str\n",
    "    first header value, the type of code (ex: vessel_carrier_code)\n",
    "variable: str\n",
    "    second header value, what the code translates to\n",
    "    **this is also the name of the file ('variable.csv')\n",
    "\n",
    "Returns:\n",
    "code_dict: dict\n",
    "    dictionary with the code as the key and the value is the translated code\n",
    "'''\n",
    "def code_dict(code_type, variable):\n",
    "    code_dict = {}\n",
    "    \n",
    "    print(\"     Cleaning \"+code_type+\" data...\")\n",
    "    \n",
    "    with open(save_folder + '/' + variable + '.csv') as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        for row in csv_reader:\n",
    "            code_dict[row[code_type]] = row[variable]\n",
    "    \n",
    "    return codeDict(code_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hardcoded things for use case\n",
    "## Table name as key, values are columns kept from original table\n",
    "tables = {\n",
    "    'billgen': ['identifier', 'voyage_number', 'trade_update_date',\n",
    "                 'run_date'],\n",
    "    'container': ['identifier', 'container_number', 'container_length', \n",
    "                'container_height', 'container_width', 'container_type',\n",
    "                 'load_status', 'type_of_service'],\n",
    "    'header': ['identifier', 'carrier_code', 'vessel_country_code', \n",
    "                'vessel_name', 'port_of_unlading','estimated_arrival_date', \n",
    "                'foreign_port_of_lading', 'manifest_quantity', 'manifest_unit', \n",
    "                'weight', 'weight_unit', 'foreign_port_of_destination',\n",
    "                 'in_bond_entry_type', 'actual_arrival_date']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv files...\n",
      "The size of 'billgen.csv' is 54215348 rows\n",
      "Saving csv file...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load all the billgen.csv files in as one Dataframe\n",
    "Remove unnecessary columns\n",
    "Save the Dataframe as a csv file\n",
    "Release the memory used by the Dataframe\n",
    "\n",
    "!!! Careful this process is memory intensive!!!\n",
    "'''\n",
    "###--------  Read in csv as Dataframe\n",
    "log_change(logfile, 'Loading in billgen.csv files')\n",
    "log_change(logfile, 'Cleaning billgen.csv')\n",
    "df, csv_files = multiple_csv_df('billgen', tables['billgen'])\n",
    "\n",
    "print(\"The size of 'billgen.csv' is \" + str(df.shape[0]) + \" rows\")\n",
    "\n",
    "###-------- Saving Dataframe as csv\n",
    "log_change(logfile, 'Saving new billgen.csv in cleaned folder')\n",
    "save_csv(df, csv_files, save_folder)\n",
    "\n",
    "\n",
    "###-------- Release Dataframe memory\n",
    "delete(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv files...\n",
      "The size of 'container.csv' uncleaned is 85503338 rows\n",
      "Cleaning 'container.csv'...\n",
      "The size of 'container.csv' cleaned is 75784281 rows\n",
      "     That's 9719057 rows removed!\n",
      "Saving csv file...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load all the container.csv files in as one Dataframe\n",
    "Clean the Dataframe\n",
    "Save the Dataframe as a csv file\n",
    "Release the memory used by the Dataframe\n",
    "\n",
    "!!! Careful this process is memory and time intensive !!!\n",
    "'''\n",
    "###--------  Read in csv as Dataframe\n",
    "log_change(logfile, 'Loading in container.csv files')\n",
    "df, csv_files = multiple_csv_df('container', tables['container'])\n",
    "og_size = df.shape[0]\n",
    "print(\"The size of 'container.csv' uncleaned is \" + str(og_size) + \" rows\")\n",
    "\n",
    "\n",
    "###--------  Cleaning\n",
    "log_change(logfile, 'Cleaning container.csv')\n",
    "print(\"Cleaning 'container.csv'...\")\n",
    "## Don't drop duplicates, sometimes one container has more than one BoL\n",
    "\n",
    "##--- Based on load_status\n",
    "# drop containers where load_status is unknown\n",
    "# change T -> Loaded, F -> Empty\n",
    "print(\" Cleaning load_status...\")\n",
    "df.dropna(subset='load_status', inplace=True)\n",
    "df.loc[(df.load_status == 'T'), 'load_status']='Loaded'\n",
    "df.loc[(df.load_status == 'F'), 'load_status']='Empty'\n",
    "\n",
    "##--- Based on invalid height/width/length\n",
    "# measurements less than 1 ft\n",
    "# get rid of inches for measurements that are 'FFFII'\n",
    "print(\" Cleaning height/width/length...\")\n",
    "invalid_index = df[(df['container_length']<1) | \n",
    "                (df['container_height']<1) | (df['container_width']<1)].index\n",
    "df.drop(invalid_index, inplace=True)\n",
    "df.loc[:, 'container_length'] = df.container_length.apply(chop_inches)\n",
    "df.loc[:, 'container_width'] = df.container_width.apply(chop_inches)\n",
    "df.loc[:, 'container_height'] = df.container_height.apply(chop_inches)\n",
    "del(invalid_index)\n",
    "\n",
    "fin_size = df.shape[0]\n",
    "print(\"The size of 'container.csv' cleaned is \" + str(fin_size) + \" rows\"\n",
    "        \"\\n     That's \" + str(og_size-fin_size) + \" rows removed!\")\n",
    "\n",
    "\n",
    "###--------  Saving Dataframe as csv\n",
    "log_change(logfile, 'Saving new container.csv in cleaned folder')\n",
    "save_csv(df, csv_files, save_folder)\n",
    "\n",
    "\n",
    "###--------  Release Dataframe memory\n",
    "delete(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv files...\n",
      "The size of 'header.csv' uncleaned is 54215348 rows\n",
      "Cleaning 'header.csv'...\n",
      "         Drop invalid rows...\n",
      "     Cleaning carrier_code data...\n",
      "     Cleaning vessel_country_code data...\n",
      "     Cleaning foreign_port_of_lading data...\n",
      "     Cleaning port_of_unlading data...\n",
      "         Splitting text...\n",
      "The size of 'container.csv' cleaned is 49085054 rows\n",
      "     That's 5130294 rows removed!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Load all the header.csv files in as one Dataframe\n",
    "Clean the Dataframe\n",
    "Save the Dataframe as a csv file\n",
    "Release the memory used by the Dataframe\n",
    "\n",
    "!!! Careful this process is memory and time intensive !!!\n",
    "'''\n",
    "###-------- Read in csv as Dataframe\n",
    "log_change(logfile, 'Loading in header.csv files')\n",
    "df, csv_files = multiple_csv_df('header', tables['header'])\n",
    "og_size = df.shape[0]\n",
    "print(\"The size of 'header.csv' uncleaned is \" + str(og_size) + \" rows\")\n",
    "\n",
    "\n",
    "###-------- Cleaning\n",
    "log_change(logfile, 'Cleaning header.csv')\n",
    "print(\"Cleaning 'header.csv'...\")\n",
    "\n",
    "##--- Drop invalid rows\n",
    "# estimated arrival date is not in 2018-2020\n",
    "print(\"     Drop invalid rows...\")\n",
    "valid_year_index = df[df['estimated_arrival_date'].str.match('2018|2019|2020')].index\n",
    "df.drop(df.index.difference(valid_year_index), inplace=True)\n",
    "delete(valid_year_index)\n",
    "\n",
    "# vessel_name, vessel_country_code drop the ones that are na\n",
    "df.dropna(subset=['vessel_name', 'vessel_country_code'], inplace=True, how='any')\n",
    "\n",
    "# in_bond_entry_type, foreign_port_of_destination\n",
    "# These are shipments where the end destination is not the US, drop them\n",
    "df = df[df['in_bond_entry_type'].isna() & df['foreign_port_of_destination'].isna()]\n",
    "df.drop(columns=['in_bond_entry_type', 'foreign_port_of_destination'], inplace=True)\n",
    "\n",
    "\n",
    "##--- Change carrier_code and vessel_country_code to actual values\n",
    "translate(df, 'carrier_code', 'carrier')\n",
    "translate(df, 'vessel_country_code', 'vessel_country')\n",
    "translate(df, 'foreign_port_of_lading', 'foreign_port_lading')\n",
    "translate(df, 'port_of_unlading', 'port_unlading')\n",
    "\n",
    "\n",
    "##--- Fix format for the port names\n",
    "# fixing wrong amount of space between commas\n",
    "print(\"     Splitting ports into seperate columns...\")\n",
    "df['port_unlading'].replace( { ',(?! )| ,' : ', ' }, inplace= True, regex = True)\n",
    "df['foreign_port_lading'].replace( { ',(?! )| ,' : ', ' }, inplace= True, regex = True)\n",
    "gc.collect()\n",
    "\n",
    "# splitting ports into city, state/country\n",
    "df[['city_foreign_port_lading','country_foreign_port_lading']] = df.foreign_port_lading.str.rsplit(\", \", expand=True, n=1)\n",
    "df[['city_port_unlading','state_port_unlading']] = df.port_unlading.str.rsplit(\", \", expand=True, n=1)\n",
    "df.drop(columns=['port_unlading', 'foreign_port_lading'], inplace=True)\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "fin_size = df.shape[0]\n",
    "print(\"The size of 'container.csv' cleaned is \" + str(fin_size) + \" rows\"\n",
    "        \"\\n     That's \" + str(og_size-fin_size) + \" rows removed!\")\n",
    "\n",
    "\n",
    "###-------- Saving Dataframe as csv\n",
    "log_change(logfile, 'Saving new header.csv in cleaned folder')\n",
    "save_csv(df, csv_files, save_folder)\n",
    "\n",
    "\n",
    "###-------- Release Dataframe memory\n",
    "delete(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bc1a11519d29b3ed6f08646f3ece60640217e649724c6bcfd38e1173c1a1bce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
